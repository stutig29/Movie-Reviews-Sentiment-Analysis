{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5HGZFjhe4F1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "673ca826-9e5b-4636-e21f-ab9d1036d29a"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ9RExIxfByt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "00dd03f6-b873-4145-a115-1d6d0aed9851"
      },
      "source": [
        "def preprocess_text(text):\n",
        "    text= re.sub(r\"^\\s+|(@[A-Za-z]+)|([^A-Za-z \\t])|(,\\w+:\\/\\/\\S+)\",\" \",text)\n",
        "    text=\" \".join(text.split())\n",
        "    text= text.lower()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    split = text.split(' ')\n",
        "    text = ' '.join([lemmatizer.lemmatize(w,'v') for w in split])    \n",
        "    return text\n",
        "    \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    no_stopword_text = [w for w in text.split() if not w in stop]\n",
        "    return ' '.join(no_stopword_text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhfA-MCifLpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "2640eadc-03f4-4877-edae-081accec6c06"
      },
      "source": [
        "train = pd.read_table(\"/content/train.tsv\")\n",
        "print(train.columns)\n",
        "print(train.shape)\n",
        "test = pd.read_table(\"/content/test.tsv\")\n",
        "print(test.columns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index(['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'], dtype='object')\n",
            "(156060, 4)\n",
            "Index(['PhraseId', 'SentenceId', 'Phrase'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9WLuCHPnBYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['Sent'] = train['Phrase'].apply(lambda x: preprocess_text(x))\n",
        "test['Sent'] = test['Phrase'].apply(lambda x: preprocess_text(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDUaLhUqnL6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "extra_stopwords = set(['none','high','pow','us','whatever','n','lrb','rrb','b'])\n",
        "stop = stop.union(extra_stopwords)\n",
        "train['Sent'] = train['Sent'].apply(lambda x: remove_stopwords(x))\n",
        "test['Sent'] =  test['Sent'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZmPBUSxn8R9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "updated_labels=[]\n",
        "for i in range(train.shape[0]):\n",
        "  if train['Sentiment'][i]==0:\n",
        "    # 1 for negative\n",
        "    updated_labels.append(1)\n",
        "  elif train['Sentiment'][i]==4:\n",
        "    # 3 for positive\n",
        "    updated_labels.append(3)\n",
        "  else:\n",
        "    # 2 for for neutral\n",
        "    updated_labels.append(train['Sentiment'][i])\n",
        "train['Sentiment']=updated_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkYtKRoVoHGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train['Sent'])):\n",
        "  if train['Sent'][i]=='':\n",
        "    train.drop([i],axis=0,inplace=True)\n",
        "train.reset_index(inplace=True)\n",
        "for i in range(len(test['Sent'])):\n",
        "  if test['Sent'][i]=='':\n",
        "    test.drop([i],axis=0,inplace=True)\n",
        "test.reset_index(inplace=True)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G-h4ET5oMtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52e4d23f-300f-4e17-cb25-538d311f9f72"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "token=Tokenizer()\n",
        "token.fit_on_texts(train['Sent'].values)\n",
        "train['vectors']=token.texts_to_sequences(train['Sent'])\n",
        "test['vectors']=token.texts_to_sequences(test['Sent'])\n",
        "#print(train['vectors'][0:5])\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "len_train = max([len(s.split()) for s in train['Sent']])\n",
        "len_test = max([len(s.split()) for s in test['Sent']])\n",
        "if len_train>len_test:\n",
        "  max_length = len_train\n",
        "else:\n",
        "  max_length = len_test\n",
        "train_vectors = pad_sequences(train['vectors'], max_length)\n",
        "test_vectors = pad_sequences(test['vectors'], max_length)\n",
        "#print(train_vectors.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bTy5ScosNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "bb935273-63f1-43c8-9314-f538b1a0378f"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "target=train.Sentiment.values\n",
        "labels=to_categorical(target-1)\n",
        "num_classes=labels.shape[1]\n",
        "print(labels)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val= train_test_split(train_vectors,labels,test_size=0.2,random_state=4)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbSWMBKEcONI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "6528538f-72d1-4883-a3f2-d0319b4ee10d"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding,GlobalAveragePooling1D\n",
        "# LSTM\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "unknown = len(token.word_index)+1\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(unknown, EMBEDDING_DIM, input_length = max_length))\n",
        "lstm_model.add(LSTM(52,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
        "lstm_model.add(GlobalAveragePooling1D())\n",
        "lstm_model.add(Dense(3, activation = 'softmax'))\n",
        "lstm_model.summary()\n",
        "\n",
        "lstm_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0824 17:59:05.056723 139746067486592 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0824 17:59:05.078194 139746067486592 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 29, 100)           1238100   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 29, 52)            31824     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 52)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 159       \n",
            "=================================================================\n",
            "Total params: 1,270,083\n",
            "Trainable params: 1,270,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahdbD_IUcTTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "outputId": "21a953d4-cc57-4276-9478-5955d316dd69"
      },
      "source": [
        "history = lstm_model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs = 20,\n",
        "                    batch_size = 512,\n",
        "                    validation_data = (x_val,y_val),\n",
        "                    verbose = 1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0824 17:59:05.784763 139746067486592 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 123544 samples, validate on 30886 samples\n",
            "Epoch 1/20\n",
            "123544/123544 [==============================] - 49s 396us/sample - loss: 0.5866 - acc: 0.7035 - val_loss: 0.5447 - val_acc: 0.7299\n",
            "Epoch 2/20\n",
            "123544/123544 [==============================] - 48s 390us/sample - loss: 0.5047 - acc: 0.7628 - val_loss: 0.4758 - val_acc: 0.7762\n",
            "Epoch 3/20\n",
            "123544/123544 [==============================] - 49s 396us/sample - loss: 0.4526 - acc: 0.7951 - val_loss: 0.4486 - val_acc: 0.7962\n",
            "Epoch 4/20\n",
            "123544/123544 [==============================] - 49s 399us/sample - loss: 0.4247 - acc: 0.8124 - val_loss: 0.4329 - val_acc: 0.8065\n",
            "Epoch 5/20\n",
            "123544/123544 [==============================] - 49s 400us/sample - loss: 0.4071 - acc: 0.8215 - val_loss: 0.4255 - val_acc: 0.8108\n",
            "Epoch 6/20\n",
            "123544/123544 [==============================] - 49s 397us/sample - loss: 0.3934 - acc: 0.8282 - val_loss: 0.4200 - val_acc: 0.8112\n",
            "Epoch 7/20\n",
            "123544/123544 [==============================] - 49s 396us/sample - loss: 0.3828 - acc: 0.8326 - val_loss: 0.4160 - val_acc: 0.8139\n",
            "Epoch 8/20\n",
            "123544/123544 [==============================] - 49s 400us/sample - loss: 0.3729 - acc: 0.8369 - val_loss: 0.4140 - val_acc: 0.8169\n",
            "Epoch 9/20\n",
            "123544/123544 [==============================] - 49s 394us/sample - loss: 0.3651 - acc: 0.8397 - val_loss: 0.4148 - val_acc: 0.8156\n",
            "Epoch 10/20\n",
            "123544/123544 [==============================] - 49s 395us/sample - loss: 0.3582 - acc: 0.8429 - val_loss: 0.4121 - val_acc: 0.8181\n",
            "Epoch 11/20\n",
            "123544/123544 [==============================] - 49s 396us/sample - loss: 0.3523 - acc: 0.8460 - val_loss: 0.4127 - val_acc: 0.8194\n",
            "Epoch 12/20\n",
            "123544/123544 [==============================] - 49s 394us/sample - loss: 0.3463 - acc: 0.8491 - val_loss: 0.4149 - val_acc: 0.8197\n",
            "Epoch 13/20\n",
            "123544/123544 [==============================] - 49s 395us/sample - loss: 0.3419 - acc: 0.8512 - val_loss: 0.4154 - val_acc: 0.8214\n",
            "Epoch 14/20\n",
            "123544/123544 [==============================] - 49s 398us/sample - loss: 0.3376 - acc: 0.8541 - val_loss: 0.4177 - val_acc: 0.8214\n",
            "Epoch 15/20\n",
            "123544/123544 [==============================] - 49s 397us/sample - loss: 0.3333 - acc: 0.8566 - val_loss: 0.4178 - val_acc: 0.8220\n",
            "Epoch 16/20\n",
            "123544/123544 [==============================] - 49s 396us/sample - loss: 0.3306 - acc: 0.8577 - val_loss: 0.4182 - val_acc: 0.8224\n",
            "Epoch 17/20\n",
            "123544/123544 [==============================] - 49s 394us/sample - loss: 0.3277 - acc: 0.8598 - val_loss: 0.4201 - val_acc: 0.8224\n",
            "Epoch 18/20\n",
            "123544/123544 [==============================] - 48s 392us/sample - loss: 0.3232 - acc: 0.8623 - val_loss: 0.4212 - val_acc: 0.8230\n",
            "Epoch 19/20\n",
            "123544/123544 [==============================] - 49s 393us/sample - loss: 0.3211 - acc: 0.8636 - val_loss: 0.4210 - val_acc: 0.8229\n",
            "Epoch 20/20\n",
            "123544/123544 [==============================] - 49s 393us/sample - loss: 0.3183 - acc: 0.8645 - val_loss: 0.4236 - val_acc: 0.8235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhDXMSwxcWyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9ffa4f10-7cc8-407c-edd3-225e57233f5d"
      },
      "source": [
        "results = lstm_model.evaluate(x_train,y_train)\n",
        "print(\"Training Accuracy\",results[1])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123544/123544 [==============================] - 26s 207us/sample - loss: 0.2956 - acc: 0.8767\n",
            "Training Accuracy 0.87674683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2lRAY9XcYjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_labels = lstm_model.predict_classes(train_vectors)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob27OapHcaSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "lstm_output = pd.DataFrame(columns=['Phrases','Actual','Predicted'])\n",
        "sent=[]\n",
        "actual_label=[]\n",
        "predicted_label=[]\n",
        "for i in range(train.shape[0]):\n",
        "  sent.append(train['Sent'][i])\n",
        "  actual_label.append(train['Sentiment'][i])\n",
        "  predicted_label.append(predict_labels[i]+1)\n",
        "lstm_output['Phrases'] = sent\n",
        "lstm_output['Actual'] = actual_label\n",
        "lstm_output['Predicted'] = predicted_label\n",
        "lstm_output.to_csv(\"/content/lstm_sa_test.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Ji7KSvqVhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}